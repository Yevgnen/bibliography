#+title: Paper notes
#+date: <2019-12-08 Sun>
#+author: Yevgnen Koh

* Han, X., Zhu, H., Yu, P., Wang, Z., Yao, Y., Liu, Z., & Sun, M. (2018): FewRel: a large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation
:PROPERTIES:
:Custom_ID: han-2018-fewrel
:END:

** 关系抽取

- Kernel Methods
- Embedding Methods
- Neural Methods
- Distant Supervision

** Few-Shot Learning

- Transfer Learning Methods
- Metric Methods
- Meta-Learning Methods

** 主要贡献

1. 将关系抽取定义成一个Few-Shot Learning任务，并提出了一个大型有监督few-shot关系抽取数据集（同一个关系的表达比较丰富）．

2. 对比多个SOTA Few-Shot Learning的关系抽取模型．

3. 用上述的模型在提出的数据集上进行评估．

** 训练策略

将已有模型与Few-Shot Learning结合的方法：

1. 微调

   在训练集上学习分类所有关系，然后在支撑集上微调．

2. k-NN

其它Few-Shot Learning方法：

1. Meta Network
2. GNN
3. SNAIL
4. Prototypical Network

** 结论

结合Few-Shot Learning的方法总是比直接使用编码器加微调或k-NN的方法要好．

* Gao, T., Han, X., Zhu, H., Liu, Z., Li, P., Sun, M., & Zhou, J. (2019): FewRel 2.0: towards more challenging few-shot relation classification
:PROPERTIES:
:Custom_ID: gao-etal-2019-fewrel-2
:END:

** 关系抽取里Few-Shot Learning的两个挑战

1. Few-shot domain adaptation (few-shot DA)

   评估Few-Shot模型的领域迁移能力．

2. Few-shot none-of-the-above detection (few-shot NOTA)

相对few-shot NOTA来说，few-shot DA目前的难度更大．

** Few-Shot Domain Adaptation

除了语料的形态与语法不一致之外，迁移过程里的两个语料库所涉及的关系集合也是不一样的．

对于few-shot DA，使用的训练语料与FewRel 1.0一样，但测试集使用新的不同领域的测试集（一个医疗领域的数据集，一个SemEval-2010 task8的数据集）．

*** 已有模型

- Subspace Mapping
- Finding Domain-Invariant Spaces
- Feature Augmentation
- Minimax Estimator
- Adversarial Training （目前比较有效）

** Few-Shot None-of-the Above Detection

NOTA通常会被当成额外的一类，识别它的难点在于由于评测的时候关系集并不是固定的，所以NOTA关系每次需要覆盖不同的语义空间．

在测试阶段所有的queries都来源于测试集，但是模型可以从训练集中采样数据作为NOTA关系的支撑集．评测使用的是FewRel 1.0的测试集而不是few-shot DA里的新测试集．

*** NOTA rate

测试集里NOTA queries所占的比例．

*** 已有模型

1. 直接把NOTA关系作为新的一类进行(\(N\) + 1)-way \(K\)-shot learning（在\(N\)类关系外的数据为NOTA采样作为支撑集）．

   效果可能不会太好，因为NOTA类的支撑集属于不同的其它关系，在特征空间里的分布比较离散．

2. BERT-PAIR

   将query与支撑集里的每一条数据进行配对拼接输入到BERT里，然后让模型输出一个二维向量分别计算这N类关系的概率与NOTA关系的概率，依旧使用交叉熵进行训练．

* Cui, L., & Zhang, Yue (2019): Hierarchically-refined label attention network for sequence labeling
:PROPERTIES:
:Custom_ID: cui-2019-bilstm-lan
:END:

Bi-LSTM-CRF并不是时时比Bi-LSTM(-softmax)好．一个可能的原因是深层句子的编码表示可能使得模型能够隐式地捕捉到长距离标签依赖．另外带CFR层可能受限于Markov假设并且解码速度受到影响．

** Bi-LSTM-LAN

1. 没有Markov假设与CRF层，输出的搜索空间巨大，指数级别．

2. 结合每个词与它标签的边缘概率建模，并且层级堆叠．

3. 模型对标签表示做attention并且与词表示一同作为隐层的输入．

4. 与Bi-LSTM的区别是：单层模型时两者等价；多层模型时，Bi-LSTM只堆叠编码器，而Bi-LSTM-LAN相当于同时堆叠softmax层．

6. 本文着重研究指数级标签序列的编码（长距离标签依赖），并且应该是首次使用层级attention网络对标签空间建模．

*** 结构

1. Bi-LSTM Encoding Sublayer

   Bi-LSTM隐层大小需要和标签表示层的大小一样．

2. Label-Attention Inference Sublayer

   #+begin_src latex :results drawer :exports results
   \begin{eqnarray}
     H^{l} & = &  \text{attention}(Q, K, V) = \alpha V \nonumber \\
     \alpha & = & \text{softmax}(\frac{QK^{T}}{\sqrt{d_{h}}}) \nonumber
   \end{eqnarray}
   #+end_src

   除了使用标准的attention之外，还可以使用multi-head attention来同时捕捉多个标签分布．

** 实验

1. 一般来说Bi-LSTM-LAN都使用两层以上，但即使只使用一层，它也比Bi-LSTM稍好，原因在于使用了标签编码．

2. 从和Bi-LSTM与Bi-LSTM-CRF的对比来看，模型的结构比模型的深度对效果的提升更重要．

3. 训练前期Bi-LSTM-LAN收敛速度比Bi-LSTM-CRF要慢一些，可能因为模型更复杂．

4. 标签表示会随着训练过程聚焦成簇．

5. Bi-LSTM学习长距离依赖相对困难，而Bi-LSTM-CRF虽然没这个问题，但对全局信息的捕捉有所欠缺．

* Shang, J., Liu, J., Jiang, M., Ren, X., Voss, C. R., & Han, J. (2017): Automated phrase mining from massive text corpora
:PROPERTIES:
:Custom_ID: shang-2017-autophrase
:END:

** 概述

1. 已有方法依赖于复杂的语言学分析器．

2. 已有的SOTA并非全自动化．

为了减少人工标注和进一步提高效果，使用了这两种方式：

1. Robust Positive-Only Distant Training

   利用知识库里的high quality phrases标注正样本和domain corpora标注负样本并建立多个独立的分类器．

2. POS-Guided Phrase Segmentation


Domain independence与lingustic knowledge之间的存在着泛化与精度矛盾．而POS tags作为一种比较浅层的语法信息，可以帮助phrasal segmentation model去定位phrase的边界．

** 主要贡献

1. 研究Automated Phrase Mining的主要挑战．

2. 提出一种robust positive-only distant training method来进行短语质量估计，以最小化人工干预．

3. 当POS tagger可用的时候，利用一种phrasal segmentation model来提高效果．

** 回顾

*** 主要问题

- Candidate Generation
- Quality Estimation

*** 相关工作

- Keyphrase Extraction
- Automatic Term Recognition
- Text Indexing Algorithms
  + Supervised Noun Phrase Chunking Techniques
  + Dependency Parsing
- Phrase Quality Estimation
- Data-driven approaches

所有这些方法依然依赖于人工．

** 预备知识

目标是开发一个自动短语挖掘的方法从大规模文档库里抽取高质量短语而无需人工标注，只需要少量的浅层语言学分析．

- 输入：语料库、知识库．
- 输出：质量从高到低排序的短语列表．

短语质量评估参考cite:liu-2015-segphrase．

AutoPhrase会根据正负样本在POS-guided phrasal segmentation前后对短语质量进行两次评估．

*** 流程

#+attr_html: :width 800px
#+attr_latex: :width 12cm
[[file:images/Shang,_J.,_Liu,_J.,_Jiang,_M.,_Ren,_X.,_Voss,_C._R.,_&_Han,_J._(2017):_Automated_phrase_mining_from_massive_text_corpora/2019-12-03_12-48-23_autophrase.png]]

**** 第一阶段

根据频率和长度的阈值在语料库里筛选出n-grams候选词，通过phrase quality estimator对其质量（主要是concordance与informativeness）进行评估．这个estimator能过统计学习所得，并独立于POS tags．

**** 第二阶段

通过phrasal segmentation为句子寻找最优切分．根据rectified frequency（这个频率表示一个短语能成完整语义单元的频率）重新计算统计特征，进行phrase quality re-estimation．这样phrase quality estimator同时也能对completeness进行评估．

* Shang, J., Liu, L., Ren, X., Gu, X., Ren, T., & Han, J. (2018): Learning named entity tagger using domain-specific dictionary
:PROPERTIES:
:Custom_ID: shang-2018-autoner
:END:

** 动机

1. 深度学习虽然减少了人工特征的需要，但依然需要大量有标注的数据．而远程监督需要减少了标注数据的需求，但产生的标签带有噪声．

   本文提出了两个模型来处理带噪声的基于词典的远程监督数据．

2. 远程监督通过一些诸如规则匹配的方法来处理实体块识别的问题，这些方法通常会导致FN较高．

   本文从语料库挖掘出高质量的短语，并将之标识为“未知”类型．而每个实体块可以带有多个类型标签．

** 主要贡献

1. 为远程监督训练提出一种Tie or Break标注方式．

2. 修改CRF层提出Fuazzy-LSTM-CRF以支持多标签的标注方式．

3. 探索了一些调整远程监督NER性能的方法，如挖掘高质量短语并用来减少FN的标签．

4. 提出的AutoNER模型仅需要词典，相对有监督方法有竞争力．

** 概述

*** 词典的构造

1. 实体词典

   1) 每一词条包含标准名与同义词．

   2) 每一词条包含实体类型．

2. 高质量短语

   通过挖掘高质量词条构造出潜在的“未知”类型实体．

*** 标签的构造

通过精确字符串匹配与最大化匹配数量来标注．

给定一个原始语料库，每一个token会被标注成以下三种中的一种：

1. 属于一种或多种已知类型．

2. 属于“未知”类型．

3. 非实体．

** 模型

*** Fuzzy-LSTM-CRF与修正版的IOBES

#+attr_html: :width 800px
#+attr_latex: :width 12cm
[[file:images/%E6%A8%A1%E5%9E%8B/2019-12-02_20-55-02_fuzzy-lstm-crf.png]]

为了支持多标签的序列，损失函数目标为极大化所有可能的标签序列的概率总和．当所有标签已知并唯一，等价于传统的CRF．

*** AutoNER与Tie or Break标注

#+attr_html: :width 800px
#+attr_latex: :width 12cm
[[file:images/Shang,_J.,_Liu,_L.,_Ren,_X.,_Gu,_X.,_Ren,_T.,_&_Han,_J._(2018):_Learning_named_entity_tagger_using_domain-specific_dictionary/2019-12-02_21-06-08_tie-or-break.png]]

Tie or Break标注主要考虑相邻token是否属于同一实体还是应该分隔：

1. Tie：如果两个token属于同一实体．

2. Unknown：至少一个token属于“未知”类型的高质量短语．

3. Break：其它情况．

任意两个Break之间形成一个token块，而每个token块与它所有的匹配类型关联．无类型关联的标记为None．

**** 动机

1. 远程监督的产生的实体边界可能会不正确，但其内部通常是正确的．

2. Unigram实体更可能为FP，但在Tie or Break的标注方式下，它们总是位于两个Break标签之间，所以不会引入错误标签的问题．

**** AutoNER流程

1. Entity Span Detection

   通过LSTM的输出与一个sigmoid层来预测Break标签．

2. Entity Type Prediction

   对齐LSTM的输出，对每一块的类型进行预测．由于每一块可能被标注有多种实体类型，所以损失函数使用了一种交叉熵的变种．

** 远程监督的优化

*** Corpus-Aware Dictionary Tailoring

针对FP：盲目使用全部词典可能会造成FP较多．这里只考虑至少出现过一次标准名的词条．

*** Unknown-Typed High-Quality Phrases

针对FN：为了减缓FN过多的问题，引入AutoPhrase抽取高质量词条添加到词典并作为潜在实体，并标注为“未知”类型．这些只有无法被这个扩展词典匹配的token块会被标记为非实体．

** 实验

只允许使用原始文本作为远程监督模型的输入．

1. AutoNER击败了上一个SOTA Distant-LSTM-CRF．

2. AutoNER性能可与有监督模型匹敌．

3. 使用[[*Corpus-Aware Dictionary Tailoring][修剪过的词典]]效果更好．

4. 添加了“未知”类型的[[*Unknown-Typed High-Quality Phrases][高质量短语]]效果也有提升．

5. 添加了gold training set之后（这里是怎么用的？），随着它数量的增多，远程监督甚至比有监督效果更好！（作者猜测远程监督可能强调实体的可匹配性，而标注数据有可能错过这些可匹配的实体．）

6. 有监督的模型需要一定数量的标注数据才达到AutoNER的相同效果．

* Wang, X., Zhang, Y., Li, Q., Ren, X., Shang, J., & Han, J. (2019). Distantly supervised biomedical named entity recognition with dictionary expansion
:PROPERTIES:
:Custom_ID: wang-2019-autobioner
:END:

** 回顾

- Fully supervised methods

  无法直接学到到新的实体类型．

- Distant supervision

  只能利用用户词典里的有限信息，尤其当词典并不完整的时候．这篇文章主要聚焦于如何通过实体集扩张处理词典不完整的问题．

- AutoBioNER

  + 不需要任何人工标注数据．

  + 依赖于一个不完整的实体字典．

  首先从用于生成候选实体的语料库与用户输入词典里挖掘统计特征用于训练数据标注．由于词典是不完整的，AutoBioNER进行自动实体集扩张用于语料库级别的实体识别和词典扩充．它将匹配到的实体作为正样本并结合上下文信息推断未能匹配的实体．扩充后的词典用于远程监督训练神经网络用于实体识别．在用户提供词典的情况下，能识别用户感兴趣的新实体．

** 贡献

- 提出了远程监督的框架AutoBioNER，能根据用户输入词典自动从大量语料库里识别生物医药的实体．

- 提出了一种实体集扩张的方法，结合自动短语挖掘与语料库级的新实体识别与词典扩充方法．

- 定性与定量词典扩充的重要性，与AutoBioNER的有效性．

** 框架

*** Phrase Mining and Dictionary Matching

**** Phrase Mining

使用AutoPhrase cite:shang-2017-autophrase 挖掘高质量短语．

**** Dictionary Matching

根据词典对挖掘到的短语进行类型匹配（在匹配过程里用到了Dictionary Tailoring cite:shang-2018-autoner ），由于词典不完整，未匹配的短语将在下一步利用匹配到的短语与未匹配到的短语的上下文相似性再次进行实体挖掘．

*** Entity Expansion

**** A Simple Way

直接利用候选短语与实体类型（即该类型下的实体集）的语义相似性．两个难点：

1. 每种实体类型集下的种子实体比较多样且稀疏．

   大的类别下可能还有很多小的类别．种子实体虽然数量庞大，但每个种子实体出现的频率相对较低，上下文信息较为稀疏，相互之间语义距离较远．（化学：药品、化学元素等．）

2. 通过短语挖掘出来的候选实体对实体集扩张来说具有噪声．有些可能的高频词实际上只是噪声（如p-value, mm, Hg等）．

**** AutoBioNER

#+attr_html: :width 800px
#+attr_latex: :width 12cm
[[file:images/Wang,_X.,_Zhang,_Y.,_Li,_Q.,_Ren,_X.,_Shang,_J.,_&_Han,_J._(2019)._Distantly_supervised_biomedical_named_entity_recognition_with_dictionary_expansion/2019-12-07_16-54-43_entity_expansion.png]]

首先对每种实体类型下的种子实体进行聚类，减少多样性与稀疏性．然后通过种子融合与特征融合减少集合扩张过程中的噪声．

The candidate entities are /ranked high for one entity type/ only if it satisfies both criteria:

1. It shares more context information with the seed entities of this type.
2. It shares context information with more seed entities of this type.

***** Semantic Closeness Scoring

语义相似性的度量：co-occurrence statistics与context features．本文在集合扩张过程同时使用两种特征．

Given a candidate phrase set \(P\) and a skip-gram (i.e. context feature) set \(C\), we define the similarity between each pair or phrase \(p\) and context \(c\) using the IF-IDF transformation cite:wang-2019-autobioner

#+begin_src latex :results drawer :exports results
\begin{eqnarray}
  f_{p, c} = \log (1 + X_{p, c})(\log |P| - \log \sum_{p' \in P} X_{p', c}), \nonumber
\end{eqnarray}
#+end_src

where \(X_{p', c}\) is the raw co-occurrence count between \(p\) and \(c\). 效果比PMI与BM25好 cite:shen-2017-setexpan．

Then the similarity between two phrases \(p_{1}\) and \(p_{2}\) under feature set \(C\) is defined as

#+begin_src latex :results drawer :exports results
\begin{eqnarray}
  \text{sim}(p_{1}, p_{2}| C) = \frac{\sum_{c \in C} \min (f_{p_{1}, c}, f_{p_{2}, c})}{\sum_{c \in C} \max (f_{p_{1}, c}, f_{p_{2}, c})}. \nonumber
\end{eqnarray}
#+end_src

Given a seed entity set \(E\) and a skip-gram feature set \(C\), each candidate phrase \(p\) can be scored as

#+begin_src latex :results drawer :exports results
\begin{eqnarray}
  \text{score}(p| E, C) = \frac{1}{|E|} \sum_{e \in E} \text{sim} (p, e| C). \nonumber
\end{eqnarray}
#+end_src

***** Seed Clustering

由于每个实体集非常多样，对某个候选短语不可能假设它离实体集里的每个元素都距离很近．所以利用\(k\)-Means根据word2vec embedding对每个实体集进行内部聚类．然后利用feature ensemble与seed ensemble为每个seed cluster进行最佳候选实体．

***** Seed Ensemble

For each \(E_{th}\), we sample \(N_{E}\) subsets \(E_{th}^{(j)} (j = 1, 2, \dots, N_{E})\). Each of the seed subsets contains \(M_{E}^{'} (M_{E}^{'} < |E_{th}|)\) features. 即对每个聚类后的种子集进行多次采样．

***** Feature Ensemble

For a context feature set \(C\), we first score each \(c \in C\) based on its accumulated strength with entities in \(E\) (i.e., \(\sum_{e \in E} f_{e, c}\)). The \(M_{C}\) skip-grams with the highest score will be selected, from which we sample \(N_{C}\) subsets \(C_{i} (i = 1, 2, \dots, N_{C})\). Each of the subsets contains \(M_{C}^{'} (M_{C}^{'} < M_{C})\) features.

For each \(C_{i}\) and \(E_{th}^{i}\), we obtain a ranking list of phrases according to their \(\text{score}(\cdot| C_{i}, E_{th}^{(j)})\). Suppose the rank of \(p\) in terms of \(\text{score}(\cdot| C_{i}, E_{th}^{(j)})\) is \(r_{pij}\), the mean reciprocal rank of \(p\) is

#+begin_src latex :results drawer :exports results
\begin{eqnarray}
  \text{MRR}(p| E_{th}) = \frac{1}{N_{C}N_{E}} \sum_{i = 1}^{N_{c}} \sum_{j = 1}^{N_{E}} \frac{1}{r_{pij}} \nonumber.
\end{eqnarray}
#+end_src

The phrases with \(\text{MRR}\) higher than a threshold \(\text{MRR}_{thrs}\) will be added into type \(E_{t}\).

*** Distant Training

参考[[#shang-2018-autoner][AutoNER]]．

** 实验

*** 主要问题

1. AutoBioNER与SOTA NER模型的对比．

2. 实体扩张的作用如何．

3. 由于AutoBioNER不需要任何人工标注数据，给定词典的时候对于新实体发现表现如何．

*** 结果

1. 纯词典匹配precision高，recall较低．

2. 进行词典扩充之后，recall有所提高．

3. 相对Fuzzy-LSTM-CRF，AutoNER在所有数据集上表现较好．

4. Dictionary-Match, Dictionary-Expansion和AutoNER可以看作AutoBioNER的框架的退化情况．通过实验证明框架里的每一模块对于提升效果都是必须的．我们要做的就是让recall的提升比precision的下降要更快．（从结果来看，AutoBioNER在precision下降的同时提高了recall．）

5. 对\(\text{MRR}\)指标选出来的实体进行了定性的分析，结果表明实体扩张选出来的实体准确率较高．

6. 对实体扩张过程里使用到的skip-grams与co-occurrence统计和直接使用word embedding两种方法的效果进行了比较．结果表明直接使用word embedding的效果不太好．因为embedding similarities只考虑语义但忽略了co-occurrence frequency．对于较低频的实体，它们的上下文比较有限，word2vec的质量可能不太好．而本文的模型同时考虑里semantics与frequency．

7. 定性分析表明对于新类型的实体，AutoBioNER通过词典的帮助能达到较高的recall．

* References

bibliographystyle:unsrt
bibliography:references.bib
